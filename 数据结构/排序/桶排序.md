# 桶排序

[TOC]

![](D:\360downloads\2054137.jpg)

## 算法简介

桶排序（Bucket sort），又称为箱排序。其是鸽巢排序的一种归纳结果。当要被排序序列内的数值是均匀分布的时候，桶排序可以达到线性时间O(n)。但桶排序并不是比较排序，它不受到比较排序O(n log n)的下限时间复杂度影响。

## 算法原理

原理一：

给定一组数字序列，找到其中最大的元素K，然后定义一个具有K+1长度的数组M（桶）。将序列中的每一个数字元素以其为M下标的方式在数组M对应的索引上+1，最后遍历数组M，即可得到排序后的结果。

原理二：

给定一组序列和M个桶，将序列中的元素尽可能均匀放到M个桶中，然后再分别对每个桶进行排序，最后再将所有桶中的元素合并。

## 算法示例

数字序列{6, 3, 7, 3, 9, 2, 4}，其中最大的元素是9，因此定义10个桶（0~9）。以序列中元素为索引，在对应桶的数加1。如下图所示：

![](images/bucket-sort-1.png)

最后遍历桶，输出桶的索引，即得到了有序的结果。

---

原理二：

序列{11, 9, 21, 8, 17, 19, 13, 1, 24, 12}，其中最大的元素是24，计算得到其第一个大于24的指数25，其幂值为5，因此定义5个桶，每个桶分别存放0~4，5~9，10~14，15~19，21-25范围的元素，然后每个桶进行比较排序。如下图所示：

![](images/bucket-sort-2.png)

最后遍历桶，即得到了有序的结果。

## 算法实现

原理一：

```java
public void bucketSort(int[] data) {
    if (data.length < 2) return;
    int max = 0, j = 0;
    for (int k : data) if (k > max) max = k;
    int[] bucket = new int[++max];
    for (int datum : data) bucket[datum]++;
    for (int i = 0; i < bucket.length; i++)
        for (int p = 0; p < bucket[i]; p++) data[j++] = i;
}
```

原理二：

桶为`LinkedList`。另外对于每个桶进行排序，为了简单起见，直接使用了`Collections.sort`函数。

```java
public void bucketSort(int[] data) {
    if (data.length < 2) return;
    int max = 0, j = 0, n = 1;
    //找出最大数
    for (int k : data) if (k > max) max = k;
    //计算最近的幂指数 - 作为桶的大小
    while ((1 << n) <= max) n++;
    //构建并初始化桶
    List<Integer>[] buckets = new LinkedList[n];
    for (int i = 0; i < n; i++) buckets[i] = new LinkedList<>();
    //按照一定的规则将元素分配到不同的桶中
    for (int datum : data) buckets[datum / n].add(datum);
    //将桶中的元素回写到原始数组中
    for (List<Integer> bucket : buckets) {
        Collections.sort(bucket);
        for (Integer d : bucket) data[j++] = d;
    }
}
```

> Note：上面实现的算法中，应用了简单的例子。在实际使用中，桶数量的计算，桶用什么数据结构，以及对每个桶用什么比较排序算法进行排序都可能是不同的，需要根据对被排序的数据的情形进行具体分析，选择合适的方式。
>
> 为了使序列中的元素尽可能均匀的分布在不同的桶中，对桶数量的的一种计算方是：首先定义固定大小的桶容量，然后以序列中的最大值减去最小值并除以桶的大小，即可得出桶的数量。

## 算法分析

桶排序可以达到O(n)的线性时间复杂度，看起来很棒，但它并没有看起来那么美好。

就“原理一”而言，其中一个问题是序列的类型只能是整数数字，因为序列中的元素需要作为桶的索引。对于最大的元素K的值而言，也不能过大，例如，如果K等于2000000000（20亿），那么我们绝不可能创建20亿长度的数组，假设数组元素是int型，占4个字节，那么大约需要7,629GB的内存空间，这将直接导致内存溢出。当然，这只是一个极端的例子。不过道理这里这样的。因此，对于被排序的序列，其**元素类型必须是整数数字，并且其数字范围0~K，K不能太大**。

就“原理二”而言，桶的数量不能过大，这也将导致每个桶中需要存储多个元素。而这样不会受到最大元素K的限制。然而却需要对每一桶进行比较排序，最后在进行合并。虽然这种方式看起来它不仅解决了原理一的问题，也应用了分治的思想，因此效率应该很高，但事实却不是如此美好。第一个问题是需要额外的辅助空间，第二个问题是我们并不能事先预知到每一个桶的大小，因此，将存在空间上的浪费，如果桶使用数组，那么将不得不面对扩容的问题。如果使用链表，对链表进行排序操作是一件很麻烦的事情，最后还是需要转换为数组进行排序。最后是每个桶还需要进行比较排序，其时间复杂度最高也只能达到O(n log n)。解决方式是需要在合理的范围尽量增大桶的数量，极限情况下是每一个桶只分配一个元素，这样就避免了桶内比较排序的操作。但桶数量太多的话，又会导致空间浪费严重。这就是一个空间和时间代价权衡的问题了。而一般情况下，我们会牺牲一定的空间来追求时间。

**时间复杂度**

原理一

首先需要遍历整个序列，找到最大元素，需要执行N次。然后再次遍历整个序列，将元素对应索引的位置加1，也需要执行N次。最后遍历所有桶，假设桶有K个，因此需要遍历K次。遍历桶的同时，也需要遍历桶中的元素数量，而这也需要执行N次。因此，最终的执行时间：T(n)=O(N+N+K+N) = O(3N+K) = O(N+K)。

原理二

首先需要遍历整个序列，找到最大元素，需要执行N次。然后构建并初始化桶，假设桶有K个，因此需要遍历K次。再然后按照一定的规则将元素分配到不同的桶中，需要执行N次。最后遍历所有桶合并元素，需要K+N次。另外还需要对每个桶进行比较排序，而比较排序的下限是O(n log n)，K个桶，需要K * O(n log n)次。最好的情况下，每个桶只有一个元素，此时O(n log n)不存在。因此，最终的执行时间：T(n)=O(N+K+N+K+N) = O(3N+2K) = O(N+K)。

**空间复杂度**

很显然，桶排序的空间复杂度为 O(N)。

**稳定性**

桶排序是一种稳定的排序算法。

## 算法应用

**案例一：如何根据年龄给100万用户排序？**

分析：对100万数据排序，如果使用比较排序，即使最快，其平均比较次数也需要O(100 W*log 100 W)≈600 W。根据对其数据的特性分析可以发现，其年龄的范围是有限的。

方法：我们假设年龄范围在1~120岁之间，创建120个桶，遍历这100万用户的年龄数据，根据年龄的大小将其放到对应的桶中，然后依次遍历这120个桶中的元素。这样就得到了按照年龄排序的100万用户数据。

**案例二：一年的全国高考考试人数为500万，分数使用标准分，最低100，最高900，没有小数，要求对这500万考生分数进行排序。**

其原理跟*案例一*是一样的。根据对数据的分析，创建800（900-100）个桶，将每个考生的分数放到f(score)=score-100的桶中，最后依次遍历这800个桶中的元素。这样就得到了按照分数排序的500万考生的分数数据。

**典型**

在一个文件中有10 G个整数，乱序排列，要求找出中位数。内存限制为2 G。只写出思路即可（内存限制为2 G意思是可以使用2 G空间来运行程序，而不考虑本机上其他软件内存占用情况。） 关于中位数：数据排序后，位置在最中间的数值。即将数据分成两部分，一部分大于该数值，一部分小于该数值。中位数的位置：当样本数为奇数时，中位数=(N+1)/2 ; 当样本数为偶数时，中位数为N/2与N/2 + 1的均值（那么10 G个数的中位数，就第5 G大的数与第5 G+1大的数的均值了）。

分析：既然要找中位数，很简单就是排序的想法。那么基于字节的桶排序是一个可行的方法。

思想：将整型的每1 byte作为一个关键字，也就是说一个整形可以拆成4个keys，而且最高位的keys越大，整数越大。如果高位keys相同，则比较次高位的keys。整个比较过程类似于字符串的[字典序](https://baike.baidu.com/item/字典序)。

**第一步**: 把10 G整数每2 G读入一次内存，然后一次遍历这536,870,912即（1024*1024*1024）*2 /4个数据。每个数据用位运算"`>>`"取出最高8位(31-24)。这8 bits(0-255)最多表示256个桶，那么可以根据8 bit的值来确定丢入第几个桶。最后把每个桶写入一个磁盘文件中，同时在内存中统计每个桶内数据的数量NUM[256]。

代价：

1. 10 G数据依次读入内存的IO代价(这个是无法避免的，CPU不能直接在磁盘上运算)。
2. 在内存中遍历536,870,912个数据，这是一个O(n)的线性时间复杂度。
3. 把256个桶写回到256个磁盘文件空间中，这个代价是额外的，也就是多付出一倍的10 G数据转移的时间。

**第二步**：根据内存中256个桶内的数量NUM[256]，计算中位数在第几个桶中。很显然，2,684,354,560个数中位数是第1,342,177,280个。假设前127个桶的数据量相加，发现少于1,342,177,280，把第128个桶数据量加上，大于1,342,177,280。说明，中位数必在磁盘的第128个桶中。而且在这个桶的第1,342,177,280~N(0~127)个数位上。N(0~127)表示前127个桶的数据量之和。然后把第128个文件中的整数读入内存。(若数据大致是均匀分布的，每个文件的大小估计在10 G/256=40 M左右，当然也不一定，但是超过2 G的可能性很小)。注意，变态的情况下，这个需要读入的第128号文件仍然大于2 G，那么整个读入仍然可以按照第一步分批来进行读取。

代价：

1. 循环计算255个桶中的数据量累加，需要O(M)的代价，其中m<255。
2. 读入一个大概80 M左右文件大小的IO代价。

**第三步**：继续以内存中的某个桶内整数的次高8 bit（他们的最高8 bit是一样的）进行桶排序(23~16)。过程和第一步相同，也是256个桶。

**第四步**：一直下去，直到最低字节(7~0 bit)的桶排序结束。我相信这个时候完全可以在内存中使用一次快排就可以了。

整个过程的时间复杂度在O(n)的线性级别上(没有任何循环嵌套)。但主要时间消耗在第一步的第二次内存-磁盘数据交换上，即10 G数据分255个文件写回磁盘上。一般而言，如果第二步过后，内存可以容纳下存在中位数的某一个文件的话，直接快排就可以了。